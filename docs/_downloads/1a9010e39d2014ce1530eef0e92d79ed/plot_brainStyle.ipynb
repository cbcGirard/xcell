{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Stylized brain\nMultiresolution meshing from an existing surface mesh.\n\nOriginal mesh, generated from MRI data, is available at [](https://3dprint.nih.gov/discover/3DPX-000320)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport xcell\nimport pyvista as pv\nimport tqdm\nfrom vtk import VTK_QUAD\n\nstl = pv.read(\"full_oriented_simpler.stl\")\n\n# pv.set_jupyter_backend(None)\n\npts = stl.points\nax = 2\n\nbbox = np.hstack((np.min(pts, axis=0), np.max(pts, axis=0)))\nxmax = np.max(np.abs(bbox)) * 1.5\n\nmindepth = 2\nmax_depth = 6\n\nsetup = xcell.Simulation(\"brain\", xmax * np.sign(bbox), True)\n\n# interpolate by bounds\nidealDepth = mindepth + (max_depth - mindepth) * (pts[:, 2] - bbox[2]) / (bbox[5] - bbox[2])\nmetfun = xcell.general_metric\n\nsetup.make_adaptive_grid(\n    ref_pts=pts,\n    max_depth=idealDepth.astype(int),\n    min_l0_function=metfun,\n    coefs=0.2 * np.ones_like(idealDepth),\n    coarsen=False,\n)\n\nsetup.finalize_mesh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adj = setup.mesh.get_element_adjacencies()\n# reg = xcell.io.Regions()\n# stl.cell_data['sigma'] = 1.\n# reg['Conductors'].append(stl)\n\n# reg.assign_sigma(setup.mesh, default_sigma=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "xmesh = xcell.io.to_vtk(setup.mesh)\n\n\nxmesh.save(\"xmesh%d%d.vtk\" % (mindepth, max_depth))\ninside = xmesh.cell_centers().select_enclosed_points(stl, tolerance=1e-9)\n\n\nfor el, s in zip(setup.mesh.elements, inside[\"SelectedPoints\"]):\n    el.sigma = s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "okfaces = []\n\nquadorders = np.array([[0, 4, 6, 2], [1, 3, 7, 5], [0, 1, 5, 4], [2, 6, 7, 3], [0, 2, 3, 1], [4, 5, 7, 6]])\n\nfor ii in tqdm.trange(len(setup.mesh.elements), desc=\"Checking faces\"):\n    el = setup.mesh.elements[ii]\n    if el.sigma > 0:\n        neighbors = adj[ii]\n\n        for jj in range(6):\n            neighbor = neighbors[jj]\n\n            for nei in neighbor:\n                if nei.sigma == 0:\n                    if nei.depth > el.depth:\n                        otherFaceInd = jj + (-1) ** jj\n                        inds = np.flip(nei.vertices[quadorders[otherFaceInd]])\n                    else:\n                        inds = el.vertices[quadorders[jj]]\n\n                    globalind = [setup.mesh.inverse_index_map[idx] for idx in inds]\n                    okfaces.append(globalind)\n\n\nfc = np.array(okfaces)\n\nusedNodes = np.unique(fc.ravel())\nrevNodes = {}\nfor ii, n in enumerate(usedNodes):\n    revNodes[n] = ii\n\nnewpts = setup.mesh.node_coords[usedNodes]\n\nnewFaces = np.array([revNodes[n] for n in fc.ravel()]).reshape((fc.shape[0], 4))\n\ncells = np.hstack((4 * np.ones((newFaces.shape[0], 1), dtype=np.uint64), newFaces.astype(np.uint64))).ravel()\ncellTypes = [VTK_QUAD] * newFaces.shape[0]\n\nqmesh = pv.UnstructuredGrid(cells, cellTypes, newpts)\nqmesh.save(\"quad.vtk\")\n\nqg = qmesh.compute_cell_sizes(length=False, volume=False)\nqg.set_active_scalars(\"Area\")\n# qg.plot(style='wireframe')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segment mesh and visualize\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fstem = \"xcell%d-%d\" % (mindepth, max_depth)\n\nresult = inside.threshold(value=0.5, scalars=\"SelectedPoints\").extract_largest()\nresult.save(fstem + \".vtk\")\n\n# obj = result.extract_surface()\n# pv.save_meshio(fstem+'.obj', obj)\npv.save_meshio(\"quads.obj\", qmesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate animation\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# to generate from premeshed file\n# result = pv.read('xcell2-9.vtk')\n\nthm = pv.themes.DarkTheme()\nthm.background = pv.Color(xcell.colors.DARK, opacity=0)\noffwhite = pv.Color(xcell.colors.OFFWHITE, opacity=1.0)\n\n\npv.set_plot_theme(thm)\n\np = pv.Plotter(off_screen=True)\np.add_mesh(stl, color=\"blue\", opacity=0.75)\n\nviewup = [0.2, -1.0, 0.0]\n\np.add_mesh(result, show_edges=False, color=offwhite)\n\np.enable_eye_dome_lighting()\n\np.show(auto_close=False)\n\npath = p.generate_orbital_path(factor=1.5, n_points=32, viewup=viewup, shift=-0.2)\n\np.open_movie(\"orbit.mp4\")\n\np.orbit_on_path(path, write_frames=True, viewup=viewup, step=0.1, progress_bar=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}